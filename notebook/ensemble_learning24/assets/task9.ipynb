{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 导论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前面的学习中，我们探讨了一系列简单而实用的回归和分类模型，同时也探讨了如何使用集成学习家族中的Bagging思想去优化最终的模型。Bagging思想的实质是：通过Bootstrap 的方式对全样本数据集进行抽样得到抽样子集，对不同的子集使用同一种基本模型进行拟合，然后投票得出最终的预测。我们也从前面的探讨知道：Bagging主要通过降低方差的方式减少预测误差。那么，本章介绍的Boosting是与Bagging截然不同的思想，Boosting方法是使用同一组数据集进行反复学习，得到一系列简单模型，然后组合这些模型构成一个预测性能十分强大的机器学习模型。显然，Boosting思想提高最终的预测效果是通过不断减少偏差的形式，与Bagging有着本质的不同。在Boosting这一大类方法中，笔者主要介绍两类常用的Boosting方式：Adaptive Boosting 和 Gradient Boosting 以及它们的变体Xgboost、LightGBM以及Catboost。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Boosting方法的基本思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在正式介绍Boosting思想之前，我想先介绍两个例子：                   \n",
    "第一个例子：不知道大家有没有做过错题本，我们将每次测验的错的题目记录在错题本上，不停的翻阅，直到我们完全掌握(也就是能够在考试中能够举一反三)。              \n",
    "第二个例子：对于一个复杂任务来说，将多个专家的判断进行适当的综合所作出的判断，要比其中任何一个专家单独判断要好。实际上这是一种“三个臭皮匠顶个诸葛亮的道理”。                 \n",
    "这两个例子都说明Boosting的道理，也就是不错地重复学习达到最终的要求。                \n",
    "Boosting的提出与发展离不开Valiant和 Kearns的努力，历史上正是Valiant和 Kearns提出了\"强可学习\"和\"弱可学习\"的概念。那什么是\"强可学习\"和\"弱可学习\"呢？在概率近似正确PAC学习的框架下：            \n",
    "  - 弱学习：识别错误率小于1/2（即准确率仅比随机猜测略高的学习算法）                     \n",
    "  - 强学习：识别准确率很高并能在多项式时间内完成的学习算法                                   \n",
    "\n",
    "非常有趣的是，在PAC 学习的框架下，强可学习和弱可学习是等价的，也就是说一个概念是强可学习的充分必要条件是这个概念是弱可学习的。这样一来，问题便是：在学习中，如果已经发现了弱可学习算法，能否将他提升至强可学习算法。因为，弱可学习算法比强可学习算法容易得多。提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器(又称为基本分类器)，然后通过一定的形式去组合这些弱分类器构成一个强分类器。大多数的Boosting方法都是通过改变训练数据集的概率分布(训练数据不同样本的权值)，针对不同概率分布的数据调用弱分类算法学习一系列的弱分类器。              \n",
    "对于Boosting方法来说，有两个问题需要给出答案：第一个是每一轮学习应该如何改变数据的概率分布，第二个是如何将各个弱分类器组合起来。关于这两个问题，不同的Boosting算法会有不同的答案，我们接下来介绍一种最经典的Boosting算法----Adaboost，我们需要理解Adaboost是怎么处理这两个问题以及为什么这么处理的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adaboost算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaboost的基本原理**                             \n",
    "\n",
    "对于Adaboost来说，解决上述的两个问题的方式是：1. 提高那些被前一轮分类器错误分类的样本的权重，而降低那些被正确分类的样本的权重。这样一来，那些在上一轮分类器中没有得到正确分类的样本，由于其权重的增大而在后一轮的训练中“备受关注”。2. 各个弱分类器的组合是通过采取加权多数表决的方式，具体来说，加大分类错误率低的弱分类器的权重，因为这些分类器能更好地完成分类任务，而减小分类错误率较大的弱分类器的权重，使其在表决中起较小的作用。                          \n",
    "现在，我们来具体介绍Adaboost算法：(参考李航老师的《统计学习方法》)                       \n",
    "假设给定一个二分类的训练数据集：$T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}$，其中每个样本点由特征与类别组成。特征$x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}$，类别$y_{i} \\in \\mathcal{Y}=\\{-1,+1\\}$，$\\mathcal{X}$是特征空间，$ \\mathcal{Y}$是类别集合，输出最终分类器$G(x)$。Adaboost算法如下：                 \n",
    "(1) 初始化训练数据的分布：$D_{1}=\\left(w_{11}, \\cdots, w_{1 i}, \\cdots, w_{1 N}\\right), \\quad w_{1 i}=\\frac{1}{N}, \\quad i=1,2, \\cdots, N$                       \n",
    "(2) 对于m=1,2,...,M            \n",
    "   - 使用具有权值分布$D_m$的训练数据集进行学习，得到基本分类器：$G_{m}(x): \\mathcal{X} \\rightarrow\\{-1,+1\\}$                  \n",
    "   - 计算$G_m(x)$在训练集上的分类误差率$e_{m}=\\sum_{i=1}^{N} P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)$                   \n",
    "   - 计算$G_m(x)$的系数$\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}$，这里的log是自然对数ln                         \n",
    "   - 更新训练数据集的权重分布                \n",
    "   $$\n",
    "   \\begin{array}{c}\n",
    "   D_{m+1}=\\left(w_{m+1,1}, \\cdots, w_{m+1, i}, \\cdots, w_{m+1, N}\\right) \\\\\n",
    "   w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, N\n",
    "   \\end{array}\n",
    "   $$                       \n",
    "   这里的$Z_m$是规范化因子，使得$D_{m+1}$称为概率分布，$Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)$                          \n",
    "\n",
    "(3) 构建基本分类器的线性组合$f(x)=\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)$，得到最终的分类器                       \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "G(x) &=\\operatorname{sign}(f(x)) \\\\\n",
    "&=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)\\right)\n",
    "\\end{aligned}\n",
    "$$                          \n",
    "\n",
    "下面对Adaboost算法做如下说明：                                            \n",
    "对于步骤(1)，假设训练数据的权值分布是均匀分布，是为了使得第一次没有先验信息的条件下每个样本在基本分类器的学习中作用一样。                         \n",
    "对于步骤(2)，每一次迭代产生的基本分类器$G_m(x)$在加权训练数据集上的分类错误率$\\begin{aligned}e_{m} &=\\sum_{i=1}^{N} P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right) =\\sum_{G_{m}\\left(x_{i}\\right) \\neq y_{i}} w_{m i}\\end{aligned}$代表了在$G_m(x)$中分类错误的样本权重和，这点直接说明了权重分布$D_m$与$G_m(x)$的分类错误率$e_m$有直接关系。同时，在步骤(2)中，计算基本分类器$G_m(x)$的系数$\\alpha_m$，$\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}$，它表示了$G_m(x)$在最终分类器的重要性程度，$\\alpha_m$的取值由基本分类器$G_m(x)$的分类错误率有直接关系，当$e_{m} \\leqslant \\frac{1}{2}$时，$\\alpha_{m} \\geqslant 0$，并且$\\alpha_m$随着$e_m$的减少而增大，因此分类错误率越小的基本分类器在最终分类器的作用越大！                       \n",
    "**最重要的，对于步骤(2)中的样本权重的更新：  **                                    \n",
    "$$\n",
    "w_{m+1, i}=\\left\\{\\begin{array}{ll}\n",
    "\\frac{w_{m i}}{Z_{m}} \\mathrm{e}^{-\\alpha_{m}}, & G_{m}\\left(x_{i}\\right)=y_{i} \\\\\n",
    "\\frac{w_{m i}}{Z_{m}} \\mathrm{e}^{\\alpha_{m}}, & G_{m}\\left(x_{i}\\right) \\neq y_{i}\n",
    "\\end{array}\\right.\n",
    "$$                        \n",
    "因此，从上式可以看到：被基本分类器$G_m(x)$错误分类的样本的权重扩大，被正确分类的样本权重减少，二者相比相差$\\mathrm{e}^{2 \\alpha_{m}}=\\frac{1-e_{m}}{e_{m}}$倍。                             \n",
    "对于步骤(3)，线性组合$f(x)$实现了将M个基本分类器的加权表决，系数$\\alpha_m$标志了基本分类器$G_m(x)$的重要性，值得注意的是：所有的$\\alpha_m$之和不为1。$f(x)$的符号决定了样本x属于哪一类。             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们使用一组简单的数据来手动计算Adaboost算法的过程：(例子来源：http://www.csie.edu.tw)                                                               \n",
    "\n",
    "训练数据如下表，假设基本分类器的形式是一个分割$x<v$或$x>v$表示，阈值v由该基本分类器在训练数据集上分类错误率$e_m$最低确定。                                                \n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "\\hline \\text { 序号 } & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\\\\n",
    "\\hline x & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\\\\n",
    "y & 1 & 1 & 1 & -1 & -1 & -1 & 1 & 1 & 1 & -1 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$                                          \n",
    "解：                        \n",
    "初始化样本权值分布\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{1} &=\\left(w_{11}, w_{12}, \\cdots, w_{110}\\right) \\\\\n",
    "w_{1 i} &=0.1, \\quad i=1,2, \\cdots, 10\n",
    "\\end{aligned}\n",
    "$$                                  \n",
    "对m=1:                      \n",
    "   - 在权值分布$D_1$的训练数据集上，遍历每个结点并计算分类误差率$e_m$，阈值取v=2.5时分类误差率最低，那么基本分类器为：\n",
    "   $$\n",
    "   G_{1}(x)=\\left\\{\\begin{array}{ll}\n",
    "   1, & x<2.5 \\\\\n",
    "   -1, & x>2.5\n",
    "   \\end{array}\\right.\n",
    "   $$                         \n",
    "   - $G_1(x)$在训练数据集上的误差率为$e_{1}=P\\left(G_{1}\\left(x_{i}\\right) \\neq y_{i}\\right)=0.3$。                                           \n",
    "   - 计算$G_1(x)$的系数：$\\alpha_{1}=\\frac{1}{2} \\log \\frac{1-e_{1}}{e_{1}}=0.4236$               \n",
    "   - 更新训练数据的权值分布：                  \n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   D_{2}=&\\left(w_{21}, \\cdots, w_{2 i}, \\cdots, w_{210}\\right) \\\\\n",
    "   w_{2 i}=& \\frac{w_{1 i}}{Z_{1}} \\exp \\left(-\\alpha_{1} y_{i} G_{1}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, 10 \\\\\n",
    "   D_{2}=&(0.07143,0.07143,0.07143,0.07143,0.07143,0.07143,\\\\\n",
    "   &0.16667,0.16667,0.16667,0.07143) \\\\\n",
    "   f_{1}(x) &=0.4236 G_{1}(x)\n",
    "   \\end{aligned}\n",
    "   $$\n",
    "\n",
    "对于m=2：                   \n",
    "   - 在权值分布$D_2$的训练数据集上，遍历每个结点并计算分类误差率$e_m$，阈值取v=8.5时分类误差率最低，那么基本分类器为：                  \n",
    "   $$\n",
    "   G_{2}(x)=\\left\\{\\begin{array}{ll}\n",
    "   1, & x<8.5 \\\\\n",
    "   -1, & x>8.5\n",
    "   \\end{array}\\right.\n",
    "   $$                       \n",
    "   - $G_2(x)$在训练数据集上的误差率为$e_2 = 0.2143$                    \n",
    "   - 计算$G_2(x)$的系数：$\\alpha_2 = 0.6496$                        \n",
    "   - 更新训练数据的权值分布：                  \n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   D_{3}=&(0.0455,0.0455,0.0455,0.1667,0.1667,0.1667\\\\\n",
    "   &0.1060,0.1060,0.1060,0.0455) \\\\\n",
    "   f_{2}(x) &=0.4236 G_{1}(x)+0.6496 G_{2}(x)\n",
    "   \\end{aligned}\n",
    "   $$                   \n",
    "   \n",
    "对m=3：                          \n",
    "   - 在权值分布$D_3$的训练数据集上，遍历每个结点并计算分类误差率$e_m$，阈值取v=5.5时分类误差率最低，那么基本分类器为：                     \n",
    "   $$\n",
    "   G_{3}(x)=\\left\\{\\begin{array}{ll}\n",
    "   1, & x>5.5 \\\\\n",
    "   -1, & x<5.5\n",
    "   \\end{array}\\right.\n",
    "   $$                               \n",
    "   - $G_3(x)$在训练数据集上的误差率为$e_3 = 0.1820$                       \n",
    "   - 计算$G_3(x)$的系数：$\\alpha_3 = 0.7514$                                 \n",
    "   - 更新训练数据的权值分布：                    \n",
    "   $$\n",
    "   D_{4}=(0.125,0.125,0.125,0.102,0.102,0.102,0.065,0.065,0.065,0.125)\n",
    "   $$                       \n",
    "   \n",
    "于是得到：$f_{3}(x)=0.4236 G_{1}(x)+0.6496 G_{2}(x)+0.7514 G_{3}(x)$，分类器$\\operatorname{sign}\\left[f_{3}(x)\\right]$在训练数据集上的误分类点的个数为0。                                \n",
    "于是得到最终分类器为：$G(x)=\\operatorname{sign}\\left[f_{3}(x)\\right]=\\operatorname{sign}\\left[0.4236 G_{1}(x)+0.6496 G_{2}(x)+0.7514 G_{3}(x)\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下面，我们使用sklearn对Adaboost算法进行建模：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次案例我们使用一份UCI的机器学习库里的开源数据集：葡萄酒数据集，该数据集可以在 ( https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data )上获得。该数据集包含了178个样本和13个特征，从不同的角度对不同的化学特性进行描述，我们的任务是根据这些数据预测红酒属于哪一个类别。(案例来源《python机器学习(第二版》)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入数据科学相关工具包：\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据：         \n",
    "wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header=None)\n",
    "wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols','Flavanoids', 'Nonflavanoid phenols', \n",
    "                'Proanthocyanins','Color intensity', 'Hue','OD280/OD315 of diluted wines','Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels [1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据查看：\n",
    "print(\"Class labels\",np.unique(wine[\"Class label\"]))\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对数据做简单解读：                    \n",
    "   - Class label：分类标签         \n",
    "   - Alcohol：酒精                   \n",
    "   - Malic acid：苹果酸                      \n",
    "   - Ash：灰                  \n",
    "   - Alcalinity of ash：灰的碱度                  \n",
    "   - Magnesium：镁                     \n",
    "   - Total phenols：总酚                      \n",
    "   - Flavanoids：黄酮类化合物                      \n",
    "   - Nonflavanoid phenols：非黄烷类酚类                      \n",
    "   - Proanthocyanins：原花青素                     \n",
    "   - Color intensity：色彩强度                 \n",
    "   - Hue：色调                       \n",
    "   - OD280/OD315 of diluted wines：稀释酒OD280 OD350                      \n",
    "   - Proline：脯氨酸                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 仅仅考虑2，3类葡萄酒，去除1类\n",
    "wine = wine[wine['Class label'] != 1]\n",
    "y = wine['Class label'].values\n",
    "X = wine[['Alcohol','OD280/OD315 of diluted wines']].values\n",
    "\n",
    "# 将分类标签变成二进制编码：\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 按8：2分割训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1,stratify=y)  # stratify参数代表了按照y的类别等比例抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 0.916/0.875\n"
     ]
    }
   ],
   "source": [
    "# 使用单一决策树建模\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "tree = tree.fit(X_train,y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "tree_train = accuracy_score(y_train,y_train_pred)\n",
    "tree_test = accuracy_score(y_test,y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' % (tree_train,tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train/test accuracies 1.000/0.917\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn实现Adaboost(基分类器为决策树)\n",
    "'''\n",
    "AdaBoostClassifier相关参数：\n",
    "base_estimator：基本分类器，默认为DecisionTreeClassifier(max_depth=1)\n",
    "n_estimators：终止迭代的次数\n",
    "learning_rate：学习率\n",
    "algorithm：训练的相关算法，{'SAMME'，'SAMME.R'}，默认='SAMME.R'\n",
    "random_state：随机种子\n",
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(base_estimator=tree,n_estimators=500,learning_rate=0.1,random_state=1)\n",
    "ada = ada.fit(X_train,y_train)\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "ada_train = accuracy_score(y_train,y_train_pred)\n",
    "ada_test = accuracy_score(y_test,y_test_pred)\n",
    "print('Adaboost train/test accuracies %.3f/%.3f' % (ada_train,ada_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果分析：单层决策树似乎对训练数据欠拟合，而Adaboost模型正确地预测了训练数据的所有分类标签，而且与单层决策树相比，Adaboost的测试性能也略有提高。然而，为什么模型在训练集和测试集的性能相差这么大呢？我们使用图像来简单说明下这个道理！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画出单层决策树与Adaboost的决策边界：\n",
    "x_min = X_train[:, 0].min() - 1\n",
    "x_max = X_train[:, 0].max() + 1\n",
    "y_min = X_train[:, 1].min() - 1\n",
    "y_max = X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n",
    "f, axarr = plt.subplots(nrows=1, ncols=2,sharex='col',sharey='row',figsize=(12, 6))\n",
    "for idx, clf, tt in zip([0, 1],[tree, ada],['Decision tree', 'Adaboost']):\n",
    "    clf.fit(X_train, y_train)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    axarr[idx].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axarr[idx].scatter(X_train[y_train==0, 0],X_train[y_train==0, 1],c='blue', marker='^')\n",
    "    axarr[idx].scatter(X_train[y_train==1, 0],X_train[y_train==1, 1],c='red', marker='o')\n",
    "    axarr[idx].set_title(tt)\n",
    "axarr[0].set_ylabel('Alcohol', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.text(0, -0.2,s='OD280/OD315 of diluted wines',ha='center',va='center',fontsize=12,transform=axarr[1].transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的决策边界图可以看到：Adaboost模型的决策边界比单层决策树的决策边界要复杂的多。也就是说，Adaboost试图用增加模型复杂度而降低偏差的方式去减少总误差，但是过程中引入了方差，可能出现国拟合，因此在训练集和测试集之间的性能存在较大的差距，这就简单地回答的刚刚问题。值的注意的是：与单个分类器相比，Adaboost等Boosting模型增加了计算的复杂度，在实践中需要仔细思考是否愿意为预测性能的相对改善而增加计算成本，而且Boosting方式无法做到现在流行的并行计算的方式进行训练，因为每一步迭代都要基于上一部的基本分类器。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
