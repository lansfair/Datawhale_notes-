{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task04 详读西瓜书+南瓜书第5章"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 神经元模型\n",
    "- 神经网络概念：  \n",
    "  &emsp;&emsp;由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物种所作出的交互反应\n",
    "- M-P神经元模型：  \n",
    "  &emsp;&emsp;每个神经元收到$n$个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接传递，神经元接收到的总输入值与该神经元阈值进行比较，然后通过激活函数处理，产生神经元的输出。\n",
    "- 激活函数常采用Sigmoid函数：$\\displaystyle \\text{sigmoid}(x)=\\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 感知机与多层网络\n",
    "- 感知机概念：  \n",
    "  &emsp;&emsp;由两层神经元组成，输入层接收外界信号后传递给输出层，输出层是M-P神经元（阈值逻辑单元）\n",
    "- 感知机学习规则：  \n",
    "  &emsp;&emsp;对训练样例$(x,y)$，若当前感知机的输出为$\\hat{y}$，则感知机权重进行如下调整：$$\n",
    "\\begin{array}{cc}\n",
    "w_i \\leftarrow  w_i + \\Delta w_i \\\\\n",
    "\\Delta w_i = \\eta(y-\\hat{y})x_i\n",
    "\\end{array}\n",
    "$$\n",
    "&emsp;&emsp;其中$\\eta \\in (0,1)$称为学习率。\n",
    "- 多层神经网络：目的是解决非线性可分问题，输出层和输入层之间的被称为隐含层，隐含层和输出层神经元都是拥有激活函数的功能神经元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 误差逆传播算法(BP算法)\n",
    "- BP算法思路：  \n",
    "  &emsp;&emsp;首先将误差反向传播给隐含层神经元，调节隐含层到输出层的连接权重与输出层神经元的阈值；接着根据隐含层神经元的均方误差，来调节输入层到隐含层的连接权值与隐含层神经元的阈值。\n",
    "- BP算法基本流程：  \n",
    "  **输入：** 训练集$D=\\{(x_k,y_k)\\}_{k=1}^m$  \n",
    "  &emsp;&emsp;&emsp; 学习率$\\eta$  \n",
    "  **过程：**  \n",
    "  (1) 在$(0,1)$范围内随机初始化网络中所有连接权和阈值；  \n",
    "  (2) **repeat**  \n",
    "  (3) &emsp;**for all** $(x_k,y_k) \\in D$ **do**  \n",
    "  (4) &emsp;&emsp;根据当前参数和$\\hat{y}_j^k = f(\\beta_j-\\theta_j)$计算当前样本的输出$\\hat{y}_k$；  \n",
    "  (5) &emsp;&emsp;根据$g_j= \\hat{y}_j^k (1-\\hat{y}_j^k )(y_j^k-\\hat{y}_j^k)$计算输出层神经元的梯度项$g_j$；  \n",
    "  (6) &emsp;&emsp;根据$\\displaystyle e_h=b_h(1-b_h)\\sum_{j=1}^l w_{hj} g_j$隐藏层神经元的梯度项$e_h$；  \n",
    "  (7) &emsp;&emsp;更新连接权$w_{hj},v_{ih}$与阈值$\\theta_j,\\gamma_h$；  \n",
    "  (8) &emsp;**end for**  \n",
    "  (9) **until** 达到停止条件  \n",
    "  **输出：** 连接权与阈值确定的多层前馈神经网络\n",
    "- BP算法更新规则：  \n",
    "  &emsp;&emsp;基于每个样本的预测值与真实类标的均方误差来进行权值调节，即每次更新只针对单个样例。其最终目标是要最小化整个训练集$D$上的累积误差，即：$\\displaystyle E=\\frac{1}{m} \\sum_{k=1}^m E_k$\n",
    "- 通过“试错法”设置隐含层神经元个数，使得多层前馈网络能够逼近连续函数。\n",
    "- 解决BP网络的过拟合：\n",
    "  1. 早停（early stopping）：将数据分为训练集与验证集，训练集用于计算梯度、更新连接权重和阈值，验证集用于评估误差，若在训练过程中，训练集误差降低，而验证集误差升高，则停止训练。\n",
    "  2. 正则化（regularization）：在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权重与阈值的平方和，其中$\\lambda \\in (0,1)$用于对经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计。\n",
    "$$E=\\lambda \\frac{1}{m} \\sum_{k=1}^m E_k+(1-\\lambda) \\sum_{i} w_i^2$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
