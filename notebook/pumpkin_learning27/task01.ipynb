{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task01 概览西瓜书+南瓜书第1、2章"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 术语梳理\n",
    "- 数据集：记录的集合\n",
    "- 样本：其中每条记录是关于一个事件或对象的描述\n",
    "- 属性/特征：反映事件或对象在某方面的表现或性质的事项\n",
    "- 学习任务分为两大类：监督学习、无监督学习\n",
    "- 独立同分布：假设样本空间中，全体样本服从一个未知“分布”，获得的每个样本都是独立地从这个分布上采样获得\n",
    "- 分类：预测值为离散值的问题\n",
    "- 回归：预测值为连续值的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 发展历程与应用\n",
    "- 推理期：20世纪50年代到70年代，逻辑理论家程序和通用问题求解程序，基于符号知识表示、通过演绎推理技术\n",
    "- 知识期：从20世纪70年代中期到80年代，专家系统问世，基于符号知识表示、通过获取和利用领域知识建立专家系统\n",
    "- 从样例中学习：20世纪90年代中期之前，基于神经网络的连接主义学习\n",
    "- 统计学习：20世纪90年代中期开始，支持向量机、核方法\n",
    "- 深度学习：21世纪初，很多层的神经网络\n",
    "- 应用：交叉学科、生物信息学、数据科学、天气预报、能源勘探、环境监测等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 经验误差与过拟合\n",
    "- 错误率：如果在$m$个样本中有$a$个样本分类错误，则错误率为$E=a/m$\n",
    "- 误差：学习器的实际预测输出与样本的真实输出之间的差异\n",
    "- 训练误差/经验误差：学习器在训练集上的误差\n",
    "- 泛化误差：学习器在新样本上的误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 评估方法\n",
    "\n",
    "### 4.1 留出法 \n",
    "- 概念：直接将数据集$D$划分为两个互斥集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S \\cup T, S \\cap T = \\emptyset$，在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计\n",
    "- 分层采样：保留类别比例的采样范式\n",
    "- 常用做法：将大约$2/3 \\sim 4/5$的样本用于训练，剩余样本用于测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 交叉验证法\n",
    "- 概念：将数据集$D$划分为$k$个大小相同的互斥子集，满足$D=D_1\\cup D_2\\cup \\cdots \\cup  D_k, \\quad D_i \\cap D_j= \\emptyset (i \\neq j)$，同样地尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。交叉验证法的思想是：每次用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集，这样就有$K$种训练集/测试集划分的情况，从而可进行$k$次训练和测试，最终返回$k$次测试结果的均值。\n",
    "\n",
    "\n",
    "- $k$最常用的取值是10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 自助法\n",
    "- 概念：给定包含$m$个样本的数据集$D$，每次随机从$D$中挑选一个样本，将其拷贝放入$D'$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到。重复执行$m$次，就可以得到了包含$m$个样本的数据集$D'$。可以得知在$m$次采样中，样本始终不被采到的概率取极限为：\n",
    "$$\n",
    "\\lim _{m \\rightarrow \\infty}\\left(1-\\frac{1}{m}\\right)^{m} \\rightarrow \\frac{1}{e} \\approx 0.368\n",
    "$$\n",
    "&emsp;&emsp;这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在$D'$中，于是可以将$D'$作为训练集，$D-D'$作为测试集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 性能度量\n",
    "\n",
    "### 5.1 错误率/精度\n",
    "- 错误率定义为$$E(f ; D)=\\frac{1}{m} \\sum_{i=1}^m I \\left(f(x_i) \\neq y_i\\right)$$\n",
    "- 精度则定义为$$\n",
    "\\begin{aligned} acc(f ; D) \n",
    "&=\\frac{1}{m} \\sum_{i=1}^{m}I\\left(f(x_i)=y_i \\right) \\\\ \n",
    "&=1-E(f ; D) \n",
    "\\end{aligned}$$&emsp;&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 查准率、查全率与F1\n",
    "- 分类混淆矩阵：  \n",
    "![分类混淆矩阵](images/ch01/01-Classification-Result-Obfuscation-Matrix.png)\n",
    "- 查准率$P$：$$P=\\frac{TP}{TP+FP}$$\n",
    "- 查全率$R$：$$R=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "\n",
    "- “P-R曲线”：描述查准/查全率变化的曲线。根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的P值和R值。\n",
    "\n",
    "\n",
    "- F1值：计算查准率与查全率的调和平均值\n",
    "$$F1=\\frac{2 \\times P \\times R}{P + R} = \\frac{2 \\times TP}{\\text{样例总数 + TP - TN}}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
